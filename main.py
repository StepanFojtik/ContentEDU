# project_structure/
# â”œâ”€â”€ .env
# â”œâ”€â”€ methodology-announcements.txt
# â”œâ”€â”€ methodology-conclusion.txt
# â”œâ”€â”€ methodology-introduction.txt
# â”œâ”€â”€ methodology-modules.txt
# â”œâ”€â”€ methodology-quiz.txt
# â”œâ”€â”€ main.py
# â””â”€â”€ requirements.txt

# ------------------ main.py -------------------
# main.py
import os
import streamlit as st
import pdfplumber
from typing import List, Dict
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import Chroma
from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain.chains import LLMChain
from langchain.prompts import PromptTemplate
from langchain_core.documents import Document
from langchain_core.messages import HumanMessage
from docx import Document as WordDocument
from dotenv import load_dotenv
import re

# ===== NaÄtenÃ­ promÄ›nnÃ½ch z .env souboru =====
load_dotenv()
API_KEY = os.getenv("OPENAI_API_KEY")

# ===== Konfigurace =====
VECTOR_DB_PATH = "vectorstore"  # cesta k vektorovÃ© databÃ¡zi
CHUNK_SIZE = 1000               # velikost chunku pÅ™i rozdÄ›lenÃ­ textu
CHUNK_OVERLAP = 100             # pÅ™ekrytÃ­ chunkÅ¯

# ===== NastavenÃ­ strÃ¡nky ve Streamlitu =====
st.set_page_config(page_title="Course Generator", layout="wide")

# ================== FUNKCE ==================

# Extrakce textu z PDF souboru pomocÃ­ pdfplumber
def extract_text_from_pdf(pdf_file) -> str:
    with pdfplumber.open(pdf_file) as pdf:
        return "\n".join([page.extract_text() or "" for page in pdf.pages])

# RozdÄ›lenÃ­ textu na menÅ¡Ã­ pÅ™ekrÃ½vajÃ­cÃ­ se chunky
def split_into_chunks(text: str) -> List[Document]:
    splitter = RecursiveCharacterTextSplitter(chunk_size=CHUNK_SIZE, chunk_overlap=CHUNK_OVERLAP)
    return splitter.create_documents([text])

# UloÅ¾enÃ­ chunkÅ¯ do vektorovÃ© databÃ¡ze (Chroma + OpenAI embeddings)
def embed_and_store_chunks(docs: List[Document]):
    embeddings = OpenAIEmbeddings(openai_api_key=API_KEY)
    vectorstore = Chroma.from_documents(docs, embeddings, persist_directory=VECTOR_DB_PATH)
    vectorstore.persist()

# NaÄtenÃ­ relevantnÃ­ho kontextu z vektorovÃ© databÃ¡ze podle dotazu
def retrieve_relevant_context(query: str, k: int = 5) -> str:
    embeddings = OpenAIEmbeddings(openai_api_key=API_KEY)
    vectorstore = Chroma(persist_directory=VECTOR_DB_PATH, embedding_function=embeddings)
    retriever = vectorstore.as_retriever(search_kwargs={"k": k})
    docs = retriever.get_relevant_documents(query)
    return "\n".join([doc.page_content for doc in docs])

# NaÄtenÃ­ textovÃ©ho souboru s metodologiÃ­ podle typu kapitoly
def load_methodology(name: str) -> str:
    path = f"methodology-{name.lower()}.txt"
    with open(path, "r", encoding="utf-8") as file:
        return file.read()

# SestavenÃ­ promptu pro LLM na zÃ¡kladÄ› kontextu, metodologie a nÃ¡zvu kapitoly
def generate_prompt(context: str, methodology: str, title: str = "", extra: str = "") -> str:
    return f"""
{methodology}

---
{f"Additional Info: {extra}\n" if extra else ""}Relevant Teaching Content:
{context}

---
Generate the response strictly based on the methodology and provided content.
"""

# OdeslÃ¡nÃ­ promptu do OpenAI GPT modelu a zÃ­skÃ¡nÃ­ odpovÄ›di
def call_gpt(prompt: str, model: str = "gpt-4") -> str:
    llm = ChatOpenAI(model=model, openai_api_key=API_KEY)
    return llm.predict(prompt)

# VygenerovÃ¡nÃ­ nÃ¡vrhu struktury kurzu na zÃ¡kladÄ› sylabu a metodologie
def generate_course_structure(course_title: str, syllabus: str, extra: str = "") -> Dict:
    context = retrieve_relevant_context(syllabus)
    methodology = load_methodology("structure")
    prompt = generate_prompt(context, methodology, course_title, extra)
    response = call_gpt(prompt, model="gpt-4")
    return {"structure": response, "context": context}

# UrÄenÃ­ typu kapitoly na zÃ¡kladÄ› nÃ¡zvu
def detect_chapter_type(title: str) -> str:
    title_lower = title.lower()
    if "announcement" in title_lower:
        return "announcements"
    elif "introduction" in title_lower:
        return "introduction"
    elif "conclusion" in title_lower:
        return "conclusion"
    elif "quiz" in title_lower:
        return "quiz"
    elif "module" in title_lower:
        return "modules"
    else:
        return "modules"  # fallback pro neznÃ¡mÃ© typy

# Extrakce jednotlivÃ½ch kapitol ze struktury do seznamu slovnÃ­kÅ¯ (nÃ¡zev + typ)
def extract_chapters(structure: str) -> List[Dict[str, str]]:
    lines = structure.strip().split("\n")
    chapters = []
    for line in lines:
        clean_line = line.strip("-â€¢ ")
        if len(clean_line) > 0:
            chapters.append({
                "title": clean_line,
                "type": detect_chapter_type(clean_line)
            })
    return chapters

# GenerovÃ¡nÃ­ obsahu celÃ©ho kurzu podle potvrzenÃ© struktury a pÅ™Ã­sluÅ¡nÃ© metodologie
def generate_full_course(structure: str, course_title: str) -> str:
    chapters = extract_chapters(structure)
    results = []

    for chapter in chapters:
        title = chapter["title"]
        chapter_type = chapter["type"]
        context = retrieve_relevant_context(title)
        methodology = load_methodology(chapter_type)
        prompt = generate_prompt(context, methodology, title=title)
        content = call_gpt(prompt, model="gpt-3.5-turbo")
        results.append(f"## {title}\n{content}")

    return "\n\n".join(results)

# Export vygenerovanÃ©ho textu do Word dokumentu
def export_to_word(text: str) -> bytes:
    doc = WordDocument()
    for para in text.split("\n"):
        doc.add_paragraph(para)
    from io import BytesIO
    buffer = BytesIO()
    doc.save(buffer)
    buffer.seek(0)
    return buffer.read()

# Export vygenerovanÃ©ho textu do HTML formÃ¡tu
def export_to_html(text: str) -> str:
    return "<html><body>" + "<br>".join(text.split("\n")) + "</body></html>"

# ================== UI ==================
st.title("ğŸ“š Moodle Course Generator")
st.markdown("Generuj kurzy na zÃ¡kladÄ› PDF a metodiky.")

# Inicializace promÄ›nnÃ½ch stavu (session)
if "structure" not in st.session_state:
    st.session_state.structure = None
if "context" not in st.session_state:
    st.session_state.context = None
if "course" not in st.session_state:
    st.session_state.course = None

# NahrÃ¡vÃ¡nÃ­ souborÅ¯ od uÅ¾ivatele
uploaded_pdfs = st.file_uploader("NahrÃ¡t PDF materiÃ¡ly", type="pdf", accept_multiple_files=True)
syllabus_file = st.file_uploader("NahrÃ¡t PDF sylabus", type="pdf")
course_title = st.text_input("NÃ¡zev kurzu")
extra_info = st.text_area("DoplÅˆujÃ­cÃ­ info (nepovinnÃ©)")

# VygenerovÃ¡nÃ­ nÃ¡vrhu struktury kurzu
if st.button("ğŸ” Vygeneruj strukturu kurzu") and uploaded_pdfs and syllabus_file and course_title:
    full_text = "\n\n".join([extract_text_from_pdf(pdf) for pdf in uploaded_pdfs])
    chunks = split_into_chunks(full_text)
    embed_and_store_chunks(chunks)

    syllabus_text = extract_text_from_pdf(syllabus_file)
    result = generate_course_structure(course_title, syllabus_text, extra_info)
    st.session_state.structure = result["structure"]
    st.session_state.context = result["context"]

# UÅ¾ivatel potvrdÃ­ nebo upravÃ­ nÃ¡vrh struktury
if st.session_state.structure:
    st.subheader("ğŸ“‘ NÃ¡vrh struktury kurzu")
    edited = st.text_area("NÃ¡vrh", st.session_state.structure, height=300)
    if st.button("âœ… Potvrdit a vytvoÅ™it obsah"):
        st.session_state.course = generate_full_course(edited, course_title)

# ZobrazenÃ­ vygenerovanÃ©ho kurzu a exportnÃ­ funkce
if st.session_state.course:
    st.subheader("ğŸ“˜ GenerovanÃ½ kurz")
    st.markdown(st.session_state.course)

    col1, col2 = st.columns(2)
    with col1:
        st.download_button("â¬‡ï¸ StÃ¡hnout jako Word", export_to_word(st.session_state.course), file_name="course.docx")
    with col2:
        st.download_button("â¬‡ï¸ StÃ¡hnout jako HTML", export_to_html(st.session_state.course), file_name="course.html", mime="text/html")

    # UÅ¾ivatel mÅ¯Å¾e zadat pÅ™ipomÃ­nku k ÃºpravÄ› vÃ½stupu
    st.subheader("ğŸ’¬ PÅ™ipomÃ­nky")
    feedback = st.text_area("Co se ti nelÃ­bÃ­?")
    if st.button("â™»ï¸ PÅ™egenerovat podle pÅ™ipomÃ­nek") and feedback:
        prompt = f"{st.session_state.context}\n\nUÅ¾ivatelskÃ¡ pÅ™ipomÃ­nka: {feedback}\n\nPÅ¯vodnÃ­ nÃ¡vrh:\n{st.session_state.course}"
        st.session_state.course = call_gpt(prompt, model="gpt-3.5-turbo")
